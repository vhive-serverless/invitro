# Trace to Proxy Function Mapper

The mapper tool can be used to map the functions in a given trace directory (with memory and duration traces) to the proxy functions in the [`vSwarm`](https://github.com/vhive-serverless/vSwarm/tree/main/) benchmark suite. The benchmarks present in the vSwarm benchmark suite have been profiled and their memory utilization and duration traces have been collected and stored in the `profile.json` file. Each function in the trace is mapped to a function in the benchmark suite as its closest proxy (based on memory and duration correlation).

The `profile.json` JSON output file is generated by the [`profiler` tool](https://github.com/vhive-serverless/vSwarm/tree/load-generator/tools/profiler#profiler) to obtain the profile of the benchmark suite functions.

### Usage

```bash
usage: mapper.py [-h] -t TRACE_DIRECTORYPATH -p PROFILE_FILEPATH [-o OUTPUT_FILEPATH] [-u UNIQUE_ASSIGNMENT]

Arguments:
  -h, --help            show this help message and exit
  -t TRACE_DIRECTORYPATH, --trace-directorypath TRACE_DIRECTORYPATH
                        Path to the directory containing the trace files (required)
  -p PROFILE_FILEPATH, --profile-filepath PROFILE_FILEPATH
                        Path to the profile file containing the proxy functions
  -o OUTPUT_FILEPATH, --output-filepath OUTPUT_FILEPATH
                        Path to the output file
  -u UNIQUE_ASSIGNMENT, --unique-assignment UNIQUE_ASSIGNMENT
                        Whether to assign unique proxy functions to each trace function
```
The tool reads the trace information(memory and duration details) from the `trace/` directory (can be configured using `-t` or `--trace-directorypath` flags). The `trace/` directory must contain the `memory.csv` and `durations.csv` files containing the respective trace information of the format mentioned in [*Azure Functions Dataset 2019*](https://github.com/Azure/AzurePublicDataset/blob/master/AzureFunctionsDataset2019.md)

#### Function Execution Duration `durations.csv` Schema

|Field|Description  |
|--|--|
| HashOwner | unique id of the application owner |
| HashApp | unique id for application name  |
| HashFunction | unique id for the function name within the app | 
|Average | Average execution time (ms) across all invocations of the 24-period|  
|Count | Number of executions used in computing the average|  
|Minimum | Minimum execution time|  
|Maximum | Maximum execution time|  
|percentile_Average_0| Weighted 0th-percentile of the execution time *average*|  
|percentile_Average_1| Weighted 1st-percentile of the execution time *average*|  
|percentile_Average_25 | Weighted 25th-percentile of the execution time *average*|  
|percentile_Average_50 | Weighted 50th-percentile of the execution time *average*|  
|percentile_Average_75 | Weighted 75th-percentile of the execution time *average*|  
|percentile_Average_99 | Weighted 99th-percentile of the execution time *average*|  
|percentile_Average_100 | Weighted 100th-percentile of the execution time *average*|
Execution time is in milliseconds. 

#### Function Memory Usage `memory.csv` Schema

|Field|Description  |
|--|--|
| HashOwner | unique id of the application owner |
| HashApp | unique id for application name  |
|SampleCount | Number of samples used for computing the average |  
|AverageAllocatedMb | Average allocated memory across all SampleCount measurements|  
|AverageAllocatedMb_pct1 | 1st percentile of the average allocated memory|  
|AverageAllocatedMb_pct5 | 5th percentile of the average allocated memory|  
|AverageAllocatedMb_pct25 | 25th percentile of the average allocated memory|  
|AverageAllocatedMb_pct50 | 50th percentile of the average allocated memory|  
|AverageAllocatedMb_pct75 | 75th percentile of the average allocated memory|  
|AverageAllocatedMb_pct95 | 95th percentile of the average allocated memory|  
|AverageAllocatedMb_pct99 | 99th percentile of the average allocated memory|  
|AverageAllocatedMb_pct100 | 100th percentile of the average allocated memory|

The [`sampler`](https://github.com/vhive-serverless/invitro/tree/main/sampler) tool in InVitro can be used to generate the sampled traces from the original Azure traces.

For every function in the trace, the closest function in the [`vSwarm`](https://github.com/vhive-serverless/vSwarm/tree/main/) benchmark suite is set as its proxy (75-percentile memory and 75-percentile duration are considered to find the highest correlation). If the `-u` (or `--unique-assignment`) flag is set to true, the tool tries to find a one-to-one (injective) mapping between trace functions and proxy functions by modelling it as a *linear sum assignment* problem which is solved by the SciPy implementation of the *Jonker-Volgenant algorithm*. If the number of trace functions is greater than the number of proxy functions, or if the mapping is not achieved, the injective constraint is removed, and the closest proxy function is obtained. Currently the tool utilizes only _Serving Functions_ that are _NOT Pipelined_ as proxy functions.

This mapping requires the profiles of the benchmark functions for it to be used as a proxy. The tool utilizes the `profile.json` JSON output file generated by the [`profiler` tool](https://github.com/vhive-serverless/vSwarm/tree/load-generator/tools/profiler#profiler) to obtain the profile of the benchmark suite functions. The User can configure the path of the JSON file through the `-p` (or `--profile-filepath`) flag (by default, it is `profile.json`).

An example of a generated output file is as follows:

```json
{
    "c13acdc7567b225971cef2416a3a2b03c8a4d8d154df48afe75834e2f5c59ddf": {
        "proxy-function": "video-processing-python-10"
    },
    "a2faad786b3c813b12ce57d349d5e62f6d0f22ceecfa86cd72a962853383b600": {
        "proxy-function": "image-rotate-go-11"
    },
    "7dc5aeabc131669912e8c793c8925cc9928321f45f13a4af031592b4611630d7": {
        "proxy-function": "video-processing-python-70"
    },
    "ae8a1640fa932024f59b38a0b001808b5c64612bd60c6f3eb80ba9461ba2d091": {
        "proxy-function": "video-processing-python-20"
    }
}
```

The default output file is `output.json` and can be configured using the `-o` (or `--output-filepath`) flag.

---